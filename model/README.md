![ML](../source/img/banner_ml.jpg)

## ğŸš€ Modelos de RecomendaciÃ³n Basados en TF-IDF: Dos Enfoques Diferentes
En la fase de Machine Learning y Data Science, hemos aplicado la tÃ©cnica TF-IDF para crear dos modelos de recomendaciÃ³n diferentes, cada uno con un enfoque distinto en el algoritmo. Â¡PrepÃ¡rate para descubrirlos! ğŸ’¡

### Modelo 1: Coincidencia de TÃ­tulo, GÃ©nero, DescripciÃ³n y Popularidad ğŸ¬ğŸ­ğŸ“ğŸ“Š
#### Paso 1: Coincidencia de TÃ­tulo
Comenzamos por seleccionar pelÃ­culas que coinciden con el tÃ­tulo ingresado. Â¡Es como buscar gemas ocultas en la base de datos! ğŸ’

#### Preprocesamiento:
Limpieza y normalizaciÃ³n de los tÃ­tulos (conversiÃ³n a minÃºsculas, eliminaciÃ³n de puntuaciÃ³n, etc.). âœ¨

#### Medida de Similitud:
UtilizaciÃ³n de tÃ©cnicas como la comparaciÃ³n de la distancia del coseno o la similitud de Jaccard para calcular la similitud entre el tÃ­tulo ingresado y los tÃ­tulos en la base de datos. ğŸ”ğŸ“Š

#### SelecciÃ³n de PelÃ­culas:
SelecciÃ³n de las pelÃ­culas con las similitudes mÃ¡s altas respecto al tÃ­tulo ingresado. ğŸ¯ğŸ¥

### Paso 2: Coincidencia de GÃ©nero
Filtramos las pelÃ­culas seleccionadas en el paso anterior basÃ¡ndonos en la similitud de gÃ©nero. Â¡AsegurÃ©monos de que las pelÃ­culas compartan su ADN cinematogrÃ¡fico! ğŸ§¬ğŸï¸

#### Preprocesamiento:
DivisiÃ³n de los gÃ©neros en palabras individuales si estÃ¡n separados por espacios. ğŸ“ƒ

#### Medida de Similitud:
UtilizaciÃ³n de medidas de similitud de texto como la distancia de Jaccard o la similitud de coseno para comparar los gÃ©neros ingresados y los gÃ©neros de las pelÃ­culas. Â¡Coincidencia de gÃ©neros! ğŸ‘¥ğŸ¥

#### Filtrado por GÃ©nero:
SelecciÃ³n de las pelÃ­culas que tienen gÃ©neros mÃ¡s similares a los ingresados. Â¡Afinando la bÃºsqueda! ğŸ”ğŸ“œ

### Paso 3: Coincidencia de DescripciÃ³n
Refinamos las pelÃ­culas seleccionadas en base a la similitud de la descripciÃ³n. Â¡Vamos mÃ¡s allÃ¡ de las palabras para encontrar verdaderas conexiones cinematogrÃ¡ficas! ğŸ“ƒâœ¨

#### Preprocesamiento:
Limpieza y normalizaciÃ³n de las descripciones, de manera similar al paso de tÃ­tulo. âœ¨

#### RepresentaciÃ³n de Descripciones:
UtilizaciÃ³n de modelos de embeddings de palabras, como Word2Vec o GloVe, para representar las descripciones como vectores. Â¡Convertimos palabras en nÃºmeros! ğŸ”¤â¡ï¸ğŸ”¢

#### Medida de Similitud:
CÃ¡lculo de la similitud entre la descripciÃ³n ingresada y las descripciones de las pelÃ­culas mediante medidas como la distancia del coseno. Â¡Comparando las esencias cinematogrÃ¡ficas! ğŸ”ğŸ¥

#### SelecciÃ³n Final:
SelecciÃ³n de las pelÃ­culas con las similitudes mÃ¡s altas en tÃ©rminos de descripciÃ³n. Â¡Las conexiones cinematogrÃ¡ficas se vuelven mÃ¡s fuertes! ğŸï¸ğŸ¤

### Paso 4: ClasificaciÃ³n por Puntaje de Popularidad
Finalmente, ordenamos las pelÃ­culas seleccionadas segÃºn su puntaje de popularidad para presentar las mejores opciones al usuario. Â¡Las favoritas del pÃºblico tienen su lugar! ğŸŒŸğŸ“Š

#### Ordenamiento:
Ordenamiento de las pelÃ­culas seleccionadas en funciÃ³n de sus puntajes de popularidad en orden descendente. Â¡Las mÃ¡s populares en la cima! ğŸ”ğŸ“Š

#### SelecciÃ³n Final:
SelecciÃ³n de las 5 pelÃ­culas principales de la lista ordenada. Â¡Las joyas del cine! ğŸ†ğŸ¬

>Este modelo nos permite abordar la recomendaciÃ³n de pelÃ­culas desde diferentes perspectivas, proporcionando a los usuarios un resultado mÃ¡s acertado. Seguiremos refinando y mejorando este modelo para brindar recomendaciones aÃºn mÃ¡s precisas y relevantes en futuras actualizaciones del proyecto. Â¡Mantente al tanto de las nuevas pelÃ­culas recomendadas! ğŸš€ğŸ¿

### ImplementaciÃ³n y OptimizaciÃ³n del Modelo de RecomendaciÃ³n
La implementaciÃ³n del modelo de recomendaciÃ³n basado en TF-IDF fue un proceso desafiante que requiriÃ³ un enfoque cuidadoso para garantizar la eficiencia y la calidad de las recomendaciones. Â¡AquÃ­ te contamos cÃ³mo lo hicimos! ğŸ’»ğŸ› ï¸

#### Puesta en Marcha y Pruebas Iniciales
Una vez definido el enfoque del modelo, procedimos a implementar el algoritmo de recomendaciÃ³n basado en TF-IDF. Sin embargo, durante las pruebas iniciales, nos enfrentamos a un problema significativo: el modelo consumÃ­a una cantidad excesiva de recursos de memoria y tiempo. Â¡Hora de solucionarlo! ğŸ•°ï¸ğŸ–¥ï¸

#### OptimizaciÃ³n a TravÃ©s de Microsoft Fabric
Para abordar este desafÃ­o, recurrimos a Microsoft Fabric, una soluciÃ³n de cÃ³mputo distribuido que nos permitiÃ³ ejecutar el algoritmo de recomendaciÃ³n en un entorno escalable. Â¡Le dimos una dosis de escalabilidad! âš™ï¸ğŸ”Œ

![8 Horas Corriendo](../source/img/8-horas-correindo-modelo-2.png)

#### OptimizaciÃ³n de Resultados Mediante PregrabaciÃ³n de Recomendaciones
En la fase de implementaciÃ³n y optimizaciÃ³n del modelo de recomendaciÃ³n, tomamos una medida estratÃ©gica para mejorar significativamente el rendimiento y la eficiencia del proceso, al pregrabar las recomendaciones para todas las pelÃ­culas en un archivo CSV. Â¡Recomendaciones listas para servir! ğŸ“¦ğŸ¬

#### Enfoque de PregrabaciÃ³n
En lugar de calcular las recomendaciones en tiempo real directamente desde el algoritmo, optamos por generar anticipadamente un conjunto de recomendaciones para todas las pelÃ­culas en un archivo CSV. Â¡AdelantÃ¡ndonos a las preferencias del usuario! ğŸ”®ğŸ“ƒ

#### JustificaciÃ³n de la PregrabaciÃ³n
El proceso de pregrabaciÃ³n se llevÃ³ a cabo debido a desafÃ­os en el rendimiento y el tiempo de ejecuciÃ³n del algoritmo en conjuntos de datos mÃ¡s grandes. Â¡Dando prioridad a la rapidez! ğŸƒâ€â™‚ï¸ğŸ“ˆ

#### Resultados y Beneficios
La pregrabaciÃ³n de recomendaciones para las pelÃ­culas permitiÃ³ la creaciÃ³n de un archivo CSV que contenÃ­a todas las recomendaciones anticipadas. Esto mejorÃ³ el rendimiento del frontend y redujo la latencia en la plataforma. Â¡Resultados rÃ¡pidos y frescos! ğŸš€ğŸ‰

#### Proceso de PregrabaciÃ³n
El proceso de generar el archivo CSV de recomendaciones para la muestra de 15,000 pelÃ­culas tomÃ³ aproximadamente 30 horas. Aunque llevÃ³ tiempo, garantizÃ³ un rendimiento eficiente y una respuesta rÃ¡pida para los usuarios. Â¡El esfuerzo valiÃ³ la pena! â³ğŸ’ª

## ğŸ”„ Modelo de RecomendaciÃ³n Optimizado: Eficiencia y Limitaciones
En la fase de desarrollo del segundo modelo de recomendaciÃ³n, empleamos un enfoque diferente para lograr eficiencia y mejoras notables en cuanto a consumo de memoria y tiempo de ejecuciÃ³n. Â¡Descubre cÃ³mo lo hicimos! ğŸ’¡ğŸš€

### CÃ³digo del Modelo NÃºmero 2
El siguiente es el cÃ³digo del segundo modelo de recomendaciÃ³n. Â¡Echa un vistazo a la magia detrÃ¡s de las recomendaciones! ğŸ’»ğŸ”

```python
def preprocess_text(text):
    return text.lower()

def calculate_cosine_similarity(matrix):
    return cosine_similarity(matrix)

def calculate_jaccard_similarity(genre_list1, genre_list2):
    intersection = len(set(genre_list1).intersection(genre_list2))
    union = len(set(genre_list1).union(genre_list2))
    return intersection / union if union != 0 else 0.0

def precompute_matrix(column, vectorizer):
    matrix = vectorizer.fit_transform(column)
    return matrix

def get_similar_movies(similarity_matrix, reference_index):
    similar_movies = list(enumerate(similarity_matrix[reference_index]))
    similar_movies = sorted(similar_movies, key=lambda x: x[1], reverse=True)
    return similar_movies

def get_top_popular_movies(df_ML):
    df_ML_sorted = df_ML.sort_values(by='popularity', ascending=False)
    top_popular_movies = df_ML_sorted.iloc[:5]
    return top_popular_movies

def recommend_movies(title, df_ML, title_to_index):
    movie_index = title_to_index.get(title)
    if movie_index is None:
        return ["No se encontrÃ³ la pelÃ­cula en la base de datos."]
    
    similar_movies_title = get_similar_movies(titulo_similarity, movie_index)
    similar_movies_genre = [(i, calculate_jaccard_similarity(df_ML['genres_clean'][movie_index], row['genres_clean']))
                            for i, row in df_ML.iterrows()]
    similar_movies_description = get_similar_movies(descripcion_similarity, movie_index)
    
    all_similarities = [(idx, (sim_title + sim_genre + sim_description) / 3.0)
                        for (idx, sim_title), (_, sim_genre), (_, sim_description)
                        in zip(similar_movies_title, similar_movies_genre, similar_movies_description)]
    all_similarities = sorted(all_similarities, key=lambda x: x[1], reverse=True)
    
    recommended_movies = []
    for idx, _ in all_similarities:
        if idx != movie_index and len(recommended_movies) < 5:
            recommended_movies.append(df_ML.iloc[idx]['title'])
    
    return recommended_movies

# Cargar los datos y realizar preprocesamiento
#df_ML = pd.read_csv("data/launch/movies.csv")
df_ML['title_clean'] = df_ML['title'].apply(preprocess_text)
df_ML['genres_clean'] = df_ML['genres_name'].apply(lambda x: [genre.lower() for genre in x.split()])
df_ML['overview_clean'] = df_ML['overview'].apply(preprocess_text)

# Preparar matrices y cÃ¡lculos de similitud
count_vectorizer = CountVectorizer(stop_words=nltk.corpus.stopwords.words('english'))
titulo_matrix = precompute_matrix(df_ML['title_clean'], count_vectorizer)
titulo_similarity = calculate_cosine_similarity(titulo_matrix)

descripcion_vectorizer = TfidfVectorizer(stop_words=nltk.corpus.stopwords.words('english'))
descripcion_matrix = precompute_matrix(df_ML['overview_clean'], descripcion_vectorizer)
descripcion_similarity = calculate_cosine_similarity(descripcion_matrix)

# Crear diccionario de indexaciÃ³n por tÃ­tulo
title_to_index = {title: idx for idx, title in enumerate(df_ML['title'])}

```

```python
recommended_movies = recommend_movies('Ariel', df_ML, title_to_index)
print(recommended_movies)
```
```python
['Open Hearts',
 'Star Trek: Nemesis',
 'Man of Iron',
 "Boys Don't Cry",
 'The Cabinet of Dr. Caligari']
```

## ğŸ” Diferencias Clave y Eficiencia

A diferencia del primer modelo que utilizÃ³ TÃ­tulo, GÃ©nero, DescripciÃ³n y Popularidad, el segundo modelo se centrÃ³ en una estrategia mÃ¡s especÃ­fica basada en la similitud de TÃ­tulo y DescripciÃ³n. Aunque el primer modelo logrÃ³ recomendaciones precisas y detalladas, enfrentamos desafÃ­os de rendimiento debido a la complejidad y los recursos requeridos.

El segundo modelo, al enfocarse en solo dos atributos, logrÃ³ un aumento significativo en la eficiencia. AquÃ­ estÃ¡n las razones clave:

ğŸ”¹ **Menos CÃ¡lculos de Similitud:** El segundo modelo calculÃ³ la similitud Ãºnicamente en base a TÃ­tulo y DescripciÃ³n, reduciendo la cantidad de cÃ¡lculos necesarios en comparaciÃ³n con el primer modelo que tambiÃ©n considerÃ³ GÃ©nero y Popularidad.

ğŸ”¹ **Uso de Jaccard en GÃ©nero:** El modelo 2 utilizÃ³ la similitud de Jaccard para comparar gÃ©neros, una medida mÃ¡s liviana en tÃ©rminos de cÃ¡lculos que las tÃ©cnicas de similitud basadas en vectores.

ğŸ”¹ **Preproceso Simplificado:** El preproceso se simplificÃ³ en el segundo modelo, enfocÃ¡ndose principalmente en la limpieza de textos y la generaciÃ³n de matrices de similitud.

ğŸ”¹ **Algoritmo de PrecomputaciÃ³n:** En lugar de precomputar recomendaciones individuales, el segundo modelo optÃ³ por precomputar matrices de similitud entre tÃ­tulos y descripciones, acelerando la generaciÃ³n de recomendaciones en tiempo real.

## ğŸš€ Ventajas y Limitaciones

El segundo modelo demostrÃ³ ser altamente eficiente en tÃ©rminos de tiempo de ejecuciÃ³n y consumo de memoria. Sin embargo, esta eficiencia vino a expensas de la diversidad y riqueza de las recomendaciones. Al centrarse en solo dos atributos, algunas pelÃ­culas relacionadas por gÃ©nero pero diferentes en otros aspectos podrÃ­an no ser consideradas en las recomendaciones.

## âš™ï¸ Consideraciones Futuras

En el futuro, continuaremos evaluando y ajustando nuestros modelos para encontrar el equilibrio Ã³ptimo entre eficiencia y calidad de recomendaciÃ³n. Estamos explorando enfoques hÃ­bridos que combinen caracterÃ­sticas clave de ambos modelos para ofrecer recomendaciones rÃ¡pidas y diversas. El camino hacia la excelencia nunca termina. ğŸŒŸğŸ”—
